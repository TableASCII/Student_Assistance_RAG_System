{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "uQx1bcKS24s1",
        "outputId": "8622b26e-d7b5-4888-e503-4c1e4328501c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.12/dist-packages (5.50.0)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.11.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.2.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.118.3)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio) (1.0.0)\n",
            "Requirement already satisfied: gradio-client==1.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.14.0)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.33.5 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.36.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.0.3)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.11.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from gradio) (25.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (11.3.0)\n",
            "Requirement already satisfied: pydantic<=2.12.3,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.12.3)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (6.0.3)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.14.6)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.7)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.48.0)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.20.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.15.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.38.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.14.0->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=13.0 in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.14.0->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (3.11)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (3.20.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<=2.12.3,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<=2.12.3,>=2.0->gradio) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<=2.12.3,>=2.0->gradio) (0.4.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (8.3.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<2.0,>=0.33.5->gradio) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<2.0,>=0.33.5->gradio) (2.5.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.13.0-cp39-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (7.7 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (25.0)\n",
            "Downloading faiss_cpu-1.13.0-cp39-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (23.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.6/23.6 MB\u001b[0m \u001b[31m89.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.13.0\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.11.12)\n"
          ]
        }
      ],
      "source": [
        "!pip install gradio\n",
        "!pip install faiss-cpu\n",
        "!pip install requests"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "lBfmGmXY1Zem"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['WANDB_DISABLED'] = 'true'"
      ],
      "metadata": {
        "id": "8SucL-Lx5vla"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Загружаем и инициализируем обученную retrieval-модель"
      ],
      "metadata": {
        "id": "l2tdRH9W-6T-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/e5-custom-trained_multilang.zip"
      ],
      "metadata": {
        "id": "G5x31jVR9EVg",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer"
      ],
      "metadata": {
        "id": "CSFJwhID7cAN"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Инициализация модели\n",
        "model = SentenceTransformer(\"/content/content/e5-custom-trained\")"
      ],
      "metadata": {
        "id": "NbX7H7BK50Vf",
        "collapsed": true
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Создание векторной БД для семантического поиска\n",
        "Создаем векторное хранилище документов с использованием FAISS, которое обеспечивает эффективный поиск текстовых фрагментов по семантической близости.\n",
        "\n",
        "Объединяем тренировочную и валидационную выборки, извлекаем из них текстовые фрагменты и добавляем префикс `passage: `, чтоб E5 лучше понимала контекст.\n",
        "\n",
        "После этого вычисляем эмбеддинги для обработанных текстов. Это нужно для вычисления близости эмбеддингов запроса пользователя и имеющимися документами в БД.\n",
        "\n",
        "И инициализируем FAISS-индекс."
      ],
      "metadata": {
        "id": "oF7Jt7cFWCYy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import faiss\n",
        "\n",
        "train_data_df = pd.read_csv(\"/content/train_data.csv\")\n",
        "val_data_df = pd.read_csv(\"/content/val_data.csv\")\n",
        "documents_df = pd.concat([train_data_df, val_data_df], ignore_index=True)\n",
        "documents = documents_df[\"positive\"].tolist()\n",
        "\n",
        "prefixed_docs = [f\"passage: {doc}\" for doc in documents]\n",
        "embeddings = model.encode(prefixed_docs, normalize_embeddings=True)\n",
        "# Создание FAISS индекса\n",
        "index = faiss.IndexFlatIP(embeddings.shape[1])\n",
        "index.add(embeddings)\n",
        "faiss.write_index(index, \"e5_faiss_index.bin\")"
      ],
      "metadata": {
        "id": "1vmuMqbZ520B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Функция `semantic_search` выполняет семантический поиск релевантных документов в векторной базе по пользовательскому запросу."
      ],
      "metadata": {
        "id": "KMyDtb1nB8bb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Функция поиска\n",
        "def semantic_search(query, top_k=12):\n",
        "    prefixed_query = f\"query: {query}\"\n",
        "    query_embedding = model.encode([prefixed_query], normalize_embeddings=True)\n",
        "    distances, indices = index.search(query_embedding, top_k)\n",
        "\n",
        "    # Убираем дубликаты из-за того, что на один абзац формируется 3 ответа\n",
        "    seen = set()\n",
        "    unique_results = []\n",
        "    for idx, dist in zip(indices[0], distances[0]):\n",
        "        doc = documents[idx]\n",
        "        if doc not in seen:\n",
        "            seen.add(doc)\n",
        "            unique_results.append((doc, float(dist)))\n",
        "\n",
        "    return unique_results"
      ],
      "metadata": {
        "id": "PLuYUg7A6dsE",
        "collapsed": true
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Отправка запроса к LLM\n",
        "Ретривер готов и теперь осталось отправить запрос к LLM, для генерации ответа по найденным релевантным документам через платформу OpenRouter.\n",
        "\n",
        "###Архитектура RAG:\n",
        "На переданнный вопрос ретривер находит релевантные документы, передает их вместе с промптом в LLM, которая генерирует финальный ответ.\n",
        "\n",
        "Задача LLM - сгенерировать ответ на заданный вопрос, используя информацию, найденную ретривером."
      ],
      "metadata": {
        "id": "Ec2D_GMuCOw6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from openai import OpenAI"
      ],
      "metadata": {
        "id": "lHxQ3lEpGmXy"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "1qwds5tB4drm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client7 = OpenAI(\n",
        "    base_url=\"https://openrouter.ai/api/v1\",\n",
        "    api_key=userdata.get('API_KEY7')\n",
        "  )"
      ],
      "metadata": {
        "id": "f3HLnfmtGupK"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_answer(question):\n",
        "    # Ищем релевантные абзацы\n",
        "    search_results = semantic_search(question, top_k=12)\n",
        "    if not search_results:\n",
        "        return \"Не удалось найти подходящую информацию\"\n",
        "\n",
        "    best_paragraph, score = search_results[0]\n",
        "    best_paragraph1, score1 = search_results[1]\n",
        "    best_paragraph2, score2 = search_results[2]\n",
        "\n",
        "\n",
        "    # Промпт\n",
        "    prompt = f\"\"\"\n",
        "    Задача:\n",
        "    Найди в предоставленных данных ответ на вопрос пользователя. Затем сформулируй ответ на вопрос пользователя.\n",
        "    Ответ должен звучать как экспертное утверждение, без упоминания источников, данных или контекста. Предоставь максимум информации используя имеющиеся данные.\n",
        "    Информации может быть мало, но даже в таком случае нужно сформулировать ответ на вопрос пользователя.\n",
        "\n",
        "    Вопрос пользователя: {question}\n",
        "    Данные для ответа:\n",
        "    1. {best_paragraph}\n",
        "    2. {best_paragraph1}\n",
        "    3. {best_paragraph2}\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # Запрос к LLM\n",
        "    completion = client7.chat.completions.create(\n",
        "      extra_body={},\n",
        "      model=\"meta-llama/llama-4-maverick:free\",\n",
        "      messages=[\n",
        "        {\n",
        "          \"role\": \"user\",\n",
        "          \"content\": [\n",
        "            {\n",
        "              \"type\": \"text\",\n",
        "              \"text\": prompt\n",
        "            }\n",
        "          ]\n",
        "        }\n",
        "      ]\n",
        "    )\n",
        "\n",
        "    # Обработка ответа\n",
        "    if completion and completion.choices:\n",
        "        content = completion.choices[0].message.content\n",
        "        return f\"\"\"\n",
        "        Ответ: {content}\\n\\n\n",
        "\n",
        "        \"\"\"\n",
        "    else:\n",
        "        print(\"Ошибка: LLM не вернул ответ\")\n"
      ],
      "metadata": {
        "id": "lXi_U_ajDvqi"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Пример работы ретривера:"
      ],
      "metadata": {
        "id": "qqr9DiKQFi_D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Пример использования\n",
        "results = semantic_search(\"Какие мероприятия в политехе?\")\n",
        "for doc, score in results:\n",
        "    print(f\"Score: {score:.4f} | {doc}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KRKMRJFNE2r9",
        "outputId": "41b475bc-9039-407a-d119-cde610d75f37"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score: 0.4839 | самое теплое мероприятие, которое как нельзя кстати проходит\n",
            "\n",
            "- «Леденец» в холодную зимнюю пору! Настоящее катание на коньках, конкурсы, призы уверены, ты уже ждешь!\n",
            "Score: 0.4328 | И это далеко не всё! В течение всего курса каждый сможет найти себе мероприятие по душе!\n",
            "Score: 0.4278 | Во время летних каникул ребят ждет отдых в спортивно-оздоровительном лагере «Ждановец». Руководство политеха активно взаимодействует со студенческим активом и студенческими объединениями.\n",
            "Score: 0.4269 | Тогда мы ждем именно тебя! У нас своя репетиционная точка, мы располагаем большим количеством инструментов и выступаем на главных мероприятиях Политеха и Ждановца, а также за их пределами.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Создание графического интерфейса\n",
        "Для обеспечения удобного взаимодействия пользователей с RAG-системой реализован веб-интерфейс с использованием библиотеки `gradio`."
      ],
      "metadata": {
        "id": "g8Lrx58TFuQK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr"
      ],
      "metadata": {
        "id": "4QpL0K-i3MTk"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iface = gr.Interface(\n",
        "    fn=generate_answer,\n",
        "    inputs=gr.Textbox(label=\"Ваш вопрос\", placeholder=\"Введите ваш вопрос здесь\"),\n",
        "    outputs=gr.Textbox(label=\"Результаты поиска\", lines=10),\n",
        "    title=\"Генерация ответов\",\n",
        "    description=\"Введите вопрос и получите релевантный ответ\"\n",
        ")\n",
        "iface.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 652
        },
        "id": "9KO1IjMY3c9V",
        "outputId": "862b4736-4dd4-4a1d-b081-cb17fe7a31e6"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://44a14ea52017d49a57.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://44a14ea52017d49a57.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    }
  ]
}